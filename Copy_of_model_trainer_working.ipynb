{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daredevil007-aks/Forex_prediction/blob/main/Copy_of_model_trainer_working.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikeras[tensorflow] --quiet\n",
        "!pip3 install datasets --quiet"
      ],
      "metadata": {
        "id": "5Q-l2V2keA3_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffb3d343-ecce-49f3-f387-3501f4e11ec9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.8/47.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m601.3/601.3 MB\u001b[0m \u001b[31m623.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m98.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m358.9/358.9 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-text 2.15.0 requires tensorflow<2.16,>=2.15.0; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.17.0 which is incompatible.\n",
            "tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.17.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.5/239.5 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.6/124.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.5/314.5 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.9/208.9 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!free -h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZ1cLTYncfJ9",
        "outputId": "acd07e17-4e0e-40c5-8366-1a1ace9cbea3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               total        used        free      shared  buff/cache   available\n",
            "Mem:            12Gi       702Mi       7.5Gi       1.0Mi       4.5Gi        11Gi\n",
            "Swap:             0B          0B          0B\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import psutil\n",
        "import os\n",
        "\n",
        "def print_memory():\n",
        "    pid = os.getpid()\n",
        "    py = psutil.Process(pid)\n",
        "    memoryUse = py.memory_info()[0] / 2.**30  # memory use in GB\n",
        "    print(f'Memory usage: {memoryUse:.2f} GB')\n",
        "\n",
        "print_memory()\n"
      ],
      "metadata": {
        "id": "uxZRXKjNh8m4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f32b686b-ddfd-4b36-fd11-4829ef09529a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memory usage: 0.09 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UDKhfFwOrKla"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Load data\n",
        "data = pd.read_csv('DAT_MS_EURUSD_M1_202407.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvfehMtKrKlc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "4e880923-1037-49a4-9795-84f2605c9cee"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'pd' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2393603995ba>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Convert `Datetime` to datetime format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Datetime'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Datetime'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ms'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Sort data by datetime just in case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Convert `Datetime` to datetime format\n",
        "data['Datetime'] = pd.to_datetime(data['Datetime'], unit='ms')\n",
        "\n",
        "# Sort data by datetime just in case\n",
        "data = data.sort_values(by='Datetime')\n",
        "\n",
        "# Use only the 'Close' prices for this example\n",
        "prices = data['Close'].values.reshape(-1, 1)\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_prices = scaler.fit_transform(prices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Wm4eztYrKld"
      },
      "outputs": [],
      "source": [
        "look_back = 24 * 60  # 5 months of minute data (approx. 30 days per month) -> changing to 24 hours for testing hptuning\n",
        "predict_forward = 5  # Predict next 5 minutes\n",
        "\n",
        "# Ensure there are enough data points\n",
        "if len(scaled_prices) < look_back + predict_forward:\n",
        "    raise ValueError(\"Not enough data points for the given look_back period.\")\n",
        "\n",
        "# Create dataset\n",
        "def create_minute_dataset(dataset, look_back, predict_forward=5):\n",
        "    X, Y = [], []\n",
        "    for i in range(len(dataset) - look_back - predict_forward):\n",
        "        # time.sleep(1)\n",
        "        a = dataset[i:(i + look_back), 0]\n",
        "        X.append(a)\n",
        "        Y.append(dataset[(i + look_back):(i + look_back + predict_forward), 0])\n",
        "    return np.array(X), np.array(Y)\n",
        "\n",
        "X, Y = create_minute_dataset(scaled_prices, look_back, predict_forward)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vr4bl3s9rKld"
      },
      "outputs": [],
      "source": [
        "X = np.reshape(X, (X.shape[0], X.shape[1], 1))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from scikeras.wrappers import KerasRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Model creation function with **kwargs to accept dynamic parameters\n",
        "def create_model(units=50, optimizer='adam', **kwargs):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(units, return_sequences=True, input_shape=(look_back, 1)))\n",
        "    model.add(LSTM(units, return_sequences=False))\n",
        "    model.add(Dense(25))\n",
        "    model.add(Dense(predict_forward))\n",
        "\n",
        "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "    return model\n",
        "\n",
        "# Create the KerasRegressor with model creation function\n",
        "model = KerasRegressor(model=create_model, verbose=0)\n",
        "\n",
        "#Define the grid search parameters\n",
        "param_grid = {\n",
        "    'model__units': [50, 100],         # Use 'model__' prefix for parameters of the model function\n",
        "    'model__optimizer': ['adam', 'rmsprop'],\n",
        "    'epochs': [10, 20],\n",
        "    'batch_size': [16, 32]\n",
        "}\n",
        "\n",
        "# Create GridSearchCV\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
        "\n",
        "# Fit the model\n",
        "X_small = X[:1000]\n",
        "Y_small = Y[:1000]\n",
        "# grid_result = grid.fit(X_small, Y_small)\n",
        "\n",
        "\n",
        "# Output the best parameters\n",
        "# print(f\"Best parameters: {grid_result.best_params_}\")\n"
      ],
      "metadata": {
        "id": "VJMEiOydyGx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# # Extract the best hyperparameters\n",
        "# best_params = grid_result.best_params_\n",
        "\n",
        "# # Retrain the model using the best parameters\n",
        "# best_model = grid_result.best_estimator_\n",
        "\n",
        "# Ensure GPU is used (if available) when fitting the model\n",
        "with tf.device('/GPU:0'):  # This ensures the model runs on the first available GPU\n",
        "    # Fit the model on the full dataset\n",
        "    model.fit(X_small, Y_small, epochs=20, batch_size=16)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyB2_5wM1Yxl",
        "outputId": "c86992f9-d5de-4868-c56b-743e2b4e43a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model\n",
        "model.model_.save('best_lstm_model.h5')\n"
      ],
      "metadata": {
        "id": "e9_uVxlQ4gDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('best_lstm_model.h5')"
      ],
      "metadata": {
        "id": "PxG6P6r5EhvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the saved model\n",
        "saved_model = load_model('best_lstm_model.h5')\n",
        "\n",
        "# Use the loaded model to make predictions\n",
        "predictions = saved_model.predict(X[-1000:])  # X_new is the new data for which you want predictions\n"
      ],
      "metadata": {
        "id": "_9cA5I5y4guB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Reshape the predictions and actual values for inverse scaling\n",
        "predictions = np.reshape(predictions, (predictions.shape[0], predict_forward))\n",
        "\n",
        "# Inverse scale the predicted values\n",
        "predicted_prices = scaler.inverse_transform(predictions)\n",
        "\n",
        "# Inverse scale the actual values for comparison\n",
        "actual_prices = scaler.inverse_transform(Y[-1000:])\n",
        "\n",
        "# Plot the actual vs predicted prices\n",
        "plt.figure(figsize=(14, 5))\n",
        "plt.plot(actual_prices.flatten(), label=\"Actual Prices\", color=\"blue\")\n",
        "plt.plot(predicted_prices.flatten(), label=\"Predicted Prices\", color=\"red\")\n",
        "plt.title(\"Forex Price Prediction (Actual vs Predicted)\")\n",
        "plt.xlabel(\"Time (minutes)\")\n",
        "plt.ylabel(\"Price\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "pk6xdsXe5ZNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from datasets import load_dataset  # Hugging Face datasets library\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras import mixed_precision\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from scikeras.wrappers import KerasRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Enable mixed precision\n",
        "policy = mixed_precision.Policy('mixed_float16')\n",
        "mixed_precision.set_global_policy(policy)\n",
        "\n",
        "# Load dataset using Hugging Face's datasets library\n",
        "dataset = load_dataset('csv', data_files='DAT_MS_EURUSD_M1_202407.csv')\n",
        "data = pd.DataFrame(dataset['train'])\n",
        "\n",
        "\n",
        "# Convert `Datetime` to datetime format\n",
        "data['Datetime'] = pd.to_datetime(data['Datetime'], format='%Y%m%d%H%M')\n",
        "\n",
        "# Use only the 'Close' prices for this example\n",
        "prices = data['Close'].values.reshape(-1, 1)\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_prices = scaler.fit_transform(prices)\n",
        "\n",
        "# Check the length of the scaled data\n",
        "print(f\"Length of minute-level data: {len(scaled_prices)}\")\n",
        "\n",
        "# Set up the look-back period (using minute-level data)\n",
        "look_back = 2 * 30 * 24 * 60  # 2 months (2 * 30 days * 24 hours * 60 minutes)\n",
        "predict_forward = 5  # Predict next 5 minutes\n",
        "\n",
        "# Ensure there are enough data points\n",
        "if len(scaled_prices) < look_back + predict_forward:\n",
        "    raise ValueError(f\"Not enough data points! Got {len(scaled_prices)}, but need at least {look_back + predict_forward}\")\n",
        "\n",
        "# Create the dataset generator\n",
        "def data_generator(dataset, look_back, predict_forward=5, batch_size=32):\n",
        "    data_len = len(dataset)\n",
        "\n",
        "    while True:\n",
        "        X, Y = [], []\n",
        "        for _ in range(batch_size):\n",
        "            i = np.random.randint(0, data_len - look_back - predict_forward)\n",
        "            X.append(dataset[i:i + look_back, 0])\n",
        "            Y.append(dataset[i + look_back:i + look_back + predict_forward, 0])\n",
        "\n",
        "        X = np.array(X).reshape(batch_size, look_back, 1)\n",
        "        Y = np.array(Y)\n",
        "        yield X, Y\n",
        "\n",
        "# Create the data generator\n",
        "train_generator = data_generator(scaled_prices, look_back, predict_forward, batch_size=32)\n",
        "steps_per_epoch = len(scaled_prices) // 32\n",
        "\n",
        "# Simplified model creation function\n",
        "def create_model(units=50, optimizer='adam', **kwargs):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(units, return_sequences=True, input_shape=(look_back, 1)))\n",
        "    model.add(LSTM(units, return_sequences=False))\n",
        "    model.add(Dense(25))\n",
        "    model.add(Dense(predict_forward))\n",
        "\n",
        "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "    return model\n",
        "\n",
        "# Keras Regressor with GridSearchCV\n",
        "model = KerasRegressor(model=create_model, verbose=0)\n",
        "\n",
        "# Grid search parameters\n",
        "param_grid = {\n",
        "    'model__units': [50, 100],\n",
        "    'model__optimizer': ['adam', 'rmsprop'],\n",
        "    'epochs': [10, 20],\n",
        "    'batch_size': [16, 32]\n",
        "}\n",
        "\n",
        "\n",
        "# GridSearchCV\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
        "\n",
        "# Fitting a smaller subset for hyperparameter tuning\n",
        "X_small = np.array([scaled_prices[i:i + look_back] for i in range(1000)])\n",
        "Y_small = np.array([scaled_prices[i + look_back:i + look_back + predict_forward] for i in range(1000)])\n",
        "X_small = np.reshape(X_small, (X_small.shape[0], X_small.shape[1], 1))\n",
        "\n",
        "# Fit GridSearchCV on a small subset\n",
        "grid_result = grid.fit(X_small, Y_small)\n",
        "\n",
        "# Best parameters\n",
        "print(f\"Best parameters: {grid_result.best_params_}\")\n",
        "\n",
        "# Early stopping and model checkpointing\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
        "checkpoint = ModelCheckpoint('best_lstm_model.h5', monitor='val_loss', save_best_only=True, verbose=1)\n",
        "\n",
        "# Use TPU if available for training\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "strategy = tf.distribute.TPUStrategy(resolver)\n",
        "\n",
        "# Train the model using the best parameters within TPU strategy\n",
        "with strategy.scope():\n",
        "    best_model = grid_result.best_estimator_\n",
        "    best_model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=steps_per_epoch,\n",
        "        epochs=20,\n",
        "        callbacks=[early_stop, checkpoint]\n",
        "    )\n",
        "\n",
        "# Save the best model\n",
        "best_model.model_.save('best_lstm_model.h5')\n",
        "\n"
      ],
      "metadata": {
        "id": "zpEbreooAflw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9ebfd5dd-7bc6-4337-fd0c-b9817c7838e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of minute-level data: 191413\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "\nAll the 48 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n48 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py\", line 770, in fit\n    self._fit(\n  File \"/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py\", line 925, in _fit\n    X, y = self._initialize(X, y)\n  File \"/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py\", line 853, in _initialize\n    X, y = self._validate_data(X, y, reset=True)\n  File \"/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py\", line 1733, in _validate_data\n    return super()._validate_data(X=X, y=y, reset=reset, y_numeric=True)\n  File \"/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py\", line 626, in _validate_data\n    X, y = check_X_y(\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 1318, in check_X_y\n    y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric, estimator=estimator)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 1328, in _check_y\n    y = check_array(\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 1058, in check_array\n    raise ValueError(\nValueError: Found array with dim 3. None expected <= 2.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-dae32bd8686a>\u001b[0m in \u001b[0;36m<cell line: 96>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;31m# Fit GridSearchCV on a small subset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_small\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_small\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;31m# Best parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 )\n\u001b[1;32m   1472\u001b[0m             ):\n\u001b[0;32m-> 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1017\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1019\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1571\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1572\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1573\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    994\u001b[0m                     )\n\u001b[1;32m    995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 996\u001b[0;31m                 \u001b[0m_warn_or_raise_about_fit_failures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m                 \u001b[0;31m# For callable self.scoring, the return type is only know after\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    527\u001b[0m                 \u001b[0;34mf\"Below are more details about the failures:\\n{fit_errors_summary}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             )\n\u001b[0;32m--> 529\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_fits_failed_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: \nAll the 48 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n48 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py\", line 770, in fit\n    self._fit(\n  File \"/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py\", line 925, in _fit\n    X, y = self._initialize(X, y)\n  File \"/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py\", line 853, in _initialize\n    X, y = self._validate_data(X, y, reset=True)\n  File \"/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py\", line 1733, in _validate_data\n    return super()._validate_data(X=X, y=y, reset=reset, y_numeric=True)\n  File \"/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py\", line 626, in _validate_data\n    X, y = check_X_y(\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 1318, in check_X_y\n    y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric, estimator=estimator)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 1328, in _check_y\n    y = check_array(\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 1058, in check_array\n    raise ValueError(\nValueError: Found array with dim 3. None expected <= 2.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "working with gridsearch"
      ],
      "metadata": {
        "id": "fDXFvbjg6aI6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from datasets import load_dataset  # Hugging Face datasets library\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.base import BaseEstimator, RegressorMixin\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras import mixed_precision\n",
        "\n",
        "# Enable mixed precision\n",
        "policy = mixed_precision.Policy('mixed_float16')\n",
        "mixed_precision.set_global_policy(policy)\n",
        "\n",
        "# Load dataset using Hugging Face's datasets library\n",
        "dataset = load_dataset('csv', data_files='DAT_MS_EURUSD_M1_202407.csv')\n",
        "data = pd.DataFrame(dataset['train'])\n",
        "\n",
        "# Convert `Datetime` to datetime format\n",
        "data['Datetime'] = pd.to_datetime(data['Datetime'], format='%Y%m%d%H%M')\n",
        "\n",
        "# Use only the 'Close' prices for this example\n",
        "prices = data['Close'].values.reshape(-1, 1)\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_prices = scaler.fit_transform(prices)\n",
        "\n",
        "# Check the length of the scaled data\n",
        "print(f\"Length of minute-level data: {len(scaled_prices)}\")\n",
        "\n",
        "# Set up the look-back period (using minute-level data)\n",
        "look_back = 2 * 30 * 24 * 60  # 2 months (2 * 30 days * 24 hours * 60 minutes)\n",
        "predict_forward = 5  # Predict next 5 minutes\n",
        "\n",
        "# Ensure there are enough data points\n",
        "if len(scaled_prices) < look_back + predict_forward:\n",
        "    raise ValueError(f\"Not enough data points! Got {len(scaled_prices)}, but need at least {look_back + predict_forward}\")\n",
        "\n",
        "# Create the dataset generator\n",
        "def data_generator(dataset, look_back, predict_forward=5, batch_size=32):\n",
        "    data_len = len(dataset)\n",
        "\n",
        "    while True:\n",
        "        X, Y = [], []\n",
        "        for _ in range(batch_size):\n",
        "            i = np.random.randint(0, data_len - look_back - predict_forward)\n",
        "            X.append(dataset[i:i + look_back, 0])\n",
        "            Y.append(dataset[i + look_back:i + look_back + predict_forward, 0])\n",
        "\n",
        "        X = np.array(X).reshape(batch_size, look_back, 1)\n",
        "        Y = np.array(Y)\n",
        "        yield X, Y\n",
        "\n",
        "# Create the data generator\n",
        "train_generator = data_generator(scaled_prices, look_back, predict_forward, batch_size=32)\n",
        "steps_per_epoch = len(scaled_prices) // 32\n",
        "\n",
        "# Custom wrapper for reshaping data for LSTM models in GridSearchCV\n",
        "from tensorflow.keras.layers import LSTM\n",
        "\n",
        "# Modify the create_model function to avoid using CuDNN in LSTM layers\n",
        "class LSTMRegressor(BaseEstimator, RegressorMixin):\n",
        "    def __init__(self, units=50, optimizer='adam', epochs=10, batch_size=32):\n",
        "        self.units = units\n",
        "        self.optimizer = optimizer\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.model_ = None  # This will store the trained model\n",
        "\n",
        "    def create_model(self):\n",
        "        model = Sequential()\n",
        "        # Disable CuDNN usage by setting use_cudnn=False\n",
        "        model.add(LSTM(self.units, return_sequences=True, input_shape=(look_back, 1), use_cudnn=False))\n",
        "        model.add(LSTM(self.units, return_sequences=False, use_cudnn=False))\n",
        "        model.add(Dense(25))\n",
        "        model.add(Dense(predict_forward, dtype='float32'))  # Mixed precision output as float32\n",
        "        model.compile(optimizer=self.optimizer, loss='mean_squared_error')\n",
        "        return model\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # Reshape the input back to 3D for LSTM\n",
        "        X = X.reshape((X.shape[0], look_back, 1))\n",
        "        self.model_ = self.create_model()\n",
        "        self.model_.fit(X, y, epochs=self.epochs, batch_size=self.batch_size, verbose=0)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        # Reshape the input back to 3D for prediction\n",
        "        X = X.reshape((X.shape[0], look_back, 1))\n",
        "        return self.model_.predict(X)\n",
        "\n",
        "\n",
        "# Keras Regressor with GridSearchCV\n",
        "model = LSTMRegressor()\n",
        "\n",
        "# Grid search parameters\n",
        "param_grid = {\n",
        "    'units': [50],\n",
        "    'optimizer': ['adam'],\n",
        "    'epochs': [10],\n",
        "    'batch_size': [8, 16]  # Reduce batch size\n",
        "}\n",
        "\n",
        "# GridSearchCV\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
        "\n",
        "# Fitting a smaller subset for hyperparameter tuning\n",
        "X_small = np.array([scaled_prices[i:i + look_back] for i in range(1000)])\n",
        "Y_small = np.array([scaled_prices[i + look_back:i + look_back + predict_forward] for i in range(1000)])\n",
        "X_small = np.reshape(X_small, (X_small.shape[0], X_small.shape[1], 1))\n",
        "\n",
        "# Fit GridSearchCV\n",
        "grid_result = grid.fit(X_small, Y_small)\n",
        "\n",
        "# Best parameters\n",
        "print(f\"Best parameters: {grid_result.best_params_}\")\n",
        "\n",
        "# Early stopping and model checkpointing\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
        "checkpoint = ModelCheckpoint('best_lstm_model.h5', monitor='val_loss', save_best_only=True, verbose=1)\n",
        "\n",
        "# Use TPU if available for training\n",
        "try:\n",
        "    resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    tf.config.experimental_connect_to_cluster(resolver)\n",
        "    tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "    strategy = tf.distribute.TPUStrategy(resolver)\n",
        "except Exception as e:\n",
        "    print(\"TPU not found, using default strategy:\", e)\n",
        "    strategy = tf.distribute.get_strategy()  # Use default strategy (e.g., GPU or CPU)\n",
        "\n",
        "# Train the model using the best parameters within TPU strategy\n",
        "with strategy.scope():\n",
        "    best_model = grid_result.best_estimator_\n",
        "    best_model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=steps_per_epoch,\n",
        "        epochs=20,\n",
        "        callbacks=[early_stop, checkpoint]\n",
        "    )\n",
        "\n",
        "# Save the best model\n",
        "best_model.model_.save('best_lstm_model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "vbOuJl1dhgWz",
        "outputId": "7b9cb75a-f505-4b10-c874-1e90968ef045"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of minute-level data: 191413\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-b52322bcc869>\u001b[0m in \u001b[0;36m<cell line: 117>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;31m# Fit GridSearchCV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_small\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_small\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;31m# Best parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 )\n\u001b[1;32m   1472\u001b[0m             ):\n\u001b[0;32m-> 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1017\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1019\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1571\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1572\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1573\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    963\u001b[0m                     )\n\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    966\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    967\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         )\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2005\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2007\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1760\u001b[0m                 (self._jobs[0].get_status(\n\u001b[1;32m   1761\u001b[0m                     timeout=self.timeout) == TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "without grid serach\n"
      ],
      "metadata": {
        "id": "W5-O_Y_s6Wmn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from datasets import load_dataset  # Hugging Face datasets library\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Input\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras import mixed_precision\n",
        "\n",
        "# Enable mixed precision\n",
        "policy = mixed_precision.Policy('mixed_float16')\n",
        "mixed_precision.set_global_policy(policy)\n",
        "\n",
        "# Load dataset using Hugging Face's datasets library\n",
        "dataset = load_dataset('csv', data_files='DAT_MS_EURUSD_M1_202407.csv')\n",
        "data = pd.DataFrame(dataset['train'])\n",
        "\n",
        "# Convert `Datetime` to datetime format\n",
        "data['Datetime'] = pd.to_datetime(data['Datetime'], format='%Y%m%d%H%M')\n",
        "\n",
        "# Use only the 'Close' prices for this example\n",
        "prices = data['Close'].values.reshape(-1, 1)\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_prices = scaler.fit_transform(prices)\n",
        "\n",
        "# Check the length of the scaled data\n",
        "print(f\"Length of minute-level data: {len(scaled_prices)}\")\n",
        "\n",
        "# Set up the look-back period (using minute-level data)\n",
        "look_back = 2 * 30 * 24 * 60  # 2 months (2 * 30 days * 24 hours * 60 minutes)\n",
        "predict_forward = 5  # Predict next 5 minutes\n",
        "\n",
        "# Ensure there are enough data points\n",
        "if len(scaled_prices) < look_back + predict_forward:\n",
        "    raise ValueError(f\"Not enough data points! Got {len(scaled_prices)}, but need at least {look_back + predict_forward}\")\n",
        "\n",
        "# Create the dataset generator\n",
        "def data_generator(dataset, look_back, predict_forward=5, batch_size=32):\n",
        "    data_len = len(dataset)\n",
        "\n",
        "    while True:\n",
        "        X, Y = [], []\n",
        "        for _ in range(batch_size):\n",
        "            i = np.random.randint(0, data_len - look_back - predict_forward)\n",
        "            X.append(dataset[i:i + look_back, 0])\n",
        "            Y.append(dataset[i + look_back:i + look_back + predict_forward, 0])\n",
        "\n",
        "        X = np.array(X).reshape(batch_size, look_back, 1)\n",
        "        Y = np.array(Y)\n",
        "        yield X, Y\n",
        "\n",
        "# Create the data generator\n",
        "train_generator = data_generator(scaled_prices, look_back, predict_forward, batch_size=32)\n",
        "steps_per_epoch = len(scaled_prices) // 32\n",
        "\n",
        "# LSTM model definition\n",
        "def create_model(units=50, optimizer='adam'):\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(look_back, 1)))  # Use Input layer instead of specifying input_shape in LSTM\n",
        "    model.add(LSTM(units, return_sequences=True))\n",
        "    model.add(LSTM(units, return_sequences=False))\n",
        "    model.add(Dense(25))\n",
        "    model.add(Dense(predict_forward, dtype='float32'))  # Mixed precision output as float32\n",
        "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "    return model\n",
        "\n",
        "# Use TPU if available for training\n",
        "try:\n",
        "    resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    tf.config.experimental_connect_to_cluster(resolver)\n",
        "    tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "    strategy = tf.distribute.TPUStrategy(resolver)\n",
        "    print(\"TPU connected and initialized.\")\n",
        "except Exception as e:\n",
        "    print(\"Error: TPU not available or not connected properly.\", e)\n",
        "    strategy = tf.distribute.get_strategy()  # Use default strategy (e.g., GPU or CPU)\n",
        "\n",
        "# Early stopping and model checkpointing\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
        "checkpoint = ModelCheckpoint('best_lstm_model.keras', monitor='val_loss', save_best_only=True, verbose=1)\n",
        "\n",
        "# Train the model using TPU strategy\n",
        "with strategy.scope():\n",
        "    model = create_model(units=50, optimizer='adam')  # Adjust units and optimizer if needed\n",
        "    model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=steps_per_epoch,\n",
        "        epochs=20,\n",
        "        callbacks=[early_stop, checkpoint]\n",
        "    )\n",
        "\n",
        "# Save the best model\n",
        "model.save('best_lstm_model.keras')\n"
      ],
      "metadata": {
        "id": "acK0rfo6rUgT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "02b7d6a2cc5945be97f159a1054206bb",
            "9635e7023f434d1483f123a48d4c7fb0",
            "ede54930c0614d639512f37b49ca1920",
            "1b96289edbe94c1da5331fdbfc6e2889",
            "94c20baef8714f418517bfa9a8a93584",
            "c0d6583ce3594721b112e508383f0546",
            "6e020300af634a05a8832e0b92e9216c",
            "5e96d631ac494403a9f47357a29da6e7",
            "14ba9d0c402f40b69573d3ae94512811",
            "efdcd2ee787b4a24a302c4b639883889",
            "a56efb7ef66d480fbea6e67db1eff517"
          ]
        },
        "outputId": "77e27206-88e6-4600-ee27-7b32a7d4727d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "02b7d6a2cc5945be97f159a1054206bb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of minute-level data: 191413\n",
            "Error: TPU not available or not connected properly. Please provide a TPU Name to connect to.\n",
            "Epoch 1/20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checking TF TPU"
      ],
      "metadata": {
        "id": "my43pnXUD8Wc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    tf.config.experimental_connect_to_cluster(resolver)\n",
        "    tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "    print(\"TPU connected successfully!\")\n",
        "except Exception as e:\n",
        "    print(\"Error: TPU not available.\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhERQLrDGlU8",
        "outputId": "ff243a54-6700-42f4-d701-3e1ad5c0ee3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: TPU not available. Please provide a TPU Name to connect to.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from datasets import load_dataset  # Hugging Face datasets library\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Input\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras import mixed_precision\n",
        "\n",
        "# Enable mixed precision\n",
        "policy = mixed_precision.Policy('mixed_float16')\n",
        "mixed_precision.set_global_policy(policy)\n",
        "\n",
        "# Load dataset using Hugging Face's datasets library\n",
        "dataset = load_dataset('csv', data_files='DAT_MS_EURUSD_M1_202407.csv')\n",
        "data = pd.DataFrame(dataset['train'])\n",
        "\n",
        "# Convert `Datetime` to datetime format\n",
        "data['Datetime'] = pd.to_datetime(data['Datetime'], format='%Y%m%d%H%M')\n",
        "\n",
        "# Use only the 'Close' prices for this example\n",
        "prices = data['Close'].values.reshape(-1, 1)\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_prices = scaler.fit_transform(prices)\n",
        "\n",
        "# Check the length of the scaled data\n",
        "print(f\"Length of minute-level data: {len(scaled_prices)}\")\n",
        "\n",
        "# Set up the look-back period\n",
        "look_back = 3 * 30 * 24 * 60  # 2 months (adjust this to reduce)\n",
        "predict_forward = 5  # Predict next 5 minutes\n",
        "\n",
        "# Ensure there are enough data points\n",
        "if len(scaled_prices) < look_back + predict_forward:\n",
        "    raise ValueError(f\"Not enough data points! Got {len(scaled_prices)}, but need at least {look_back + predict_forward}\")\n",
        "\n",
        "# Create the dataset generator\n",
        "def data_generator(dataset, look_back, predict_forward=5, batch_size=32):\n",
        "    data_len = len(dataset)\n",
        "\n",
        "    while True:\n",
        "        X, Y = [], []\n",
        "        for _ in range(batch_size):\n",
        "            i = np.random.randint(0, data_len - look_back - predict_forward)\n",
        "            X.append(dataset[i:i + look_back, 0])\n",
        "            Y.append(dataset[i + look_back:i + look_back + predict_forward, 0])\n",
        "\n",
        "        X = np.array(X).reshape(batch_size, look_back, 1)\n",
        "        Y = np.array(Y)\n",
        "        yield X, Y\n",
        "\n",
        "# Create the data generator\n",
        "train_generator = data_generator(scaled_prices, look_back, predict_forward, batch_size=32)\n",
        "steps_per_epoch = len(scaled_prices) // 32\n",
        "\n",
        "# LSTM model definition (reduced size)\n",
        "def create_model(units=250, optimizer='adam'):  # Reduce units to 128\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(look_back, 1)))  # Use Input layer instead of specifying input_shape in LSTM\n",
        "    model.add(LSTM(units, return_sequences=True))\n",
        "    model.add(LSTM(units // 2, return_sequences=False))  # Halve the units for the second LSTM layer\n",
        "    model.add(Dense(25))\n",
        "    model.add(Dense(predict_forward, dtype='float32'))  # Mixed precision output as float32\n",
        "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "    return model\n",
        "\n",
        "# Use default strategy (e.g., GPU or CPU)\n",
        "strategy = tf.distribute.get_strategy()\n",
        "\n",
        "# Early stopping and model checkpointing\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n",
        "checkpoint = ModelCheckpoint('best_lstm_model.keras', monitor='val_loss', save_best_only=True, verbose=1)\n",
        "\n",
        "# Train the model using the default strategy\n",
        "with strategy.scope():\n",
        "    model = create_model(units=250, optimizer='adam')  # Reduced unitsz\n",
        "\n",
        "    model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=steps_per_epoch,\n",
        "        epochs=20,\n",
        "        callbacks=[early_stop, checkpoint]\n",
        "    )\n",
        "\n",
        "# Save the best model\n",
        "model.save('best_lstm_model.keras')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "cb129d85bf6a4f228965b311a792e711",
            "773ee67448194509826fc2a27db3f617",
            "676148fc7c7440ddae89dc7a79ba7ef3",
            "f0310138cb9a4d49b92a0f4503e5442f",
            "fc0aefeabbea4ae4bd2785570bfbe4dc",
            "c92d90add2e045fab512573d0eb3ff9d",
            "a09d683934db45f58e891491a72b2641",
            "55c88ed51f394f199dd33ba799072697",
            "e69334e8826042cc97c07503ba73986a",
            "c7a24f48d2994d7990d66172362bb431",
            "9e4855ea874e4828a8bf07dd440fa95c"
          ]
        },
        "id": "cRN7dxAPFR-N",
        "outputId": "54d932c0-cde3-42c6-b8a7-45f4fcd405f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cb129d85bf6a4f228965b311a792e711"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of minute-level data: 191413\n",
            "Epoch 1/20\n",
            "\u001b[1m   4/5981\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4350:03:09\u001b[0m 2620s/step - loss: 0.2226"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jlO-mGNFM3or"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "63963b3f4c440940f0b94a3100916033a226cb4f45979123153792d60aa56d6a"
      }
    },
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "include_colab_link": true
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02b7d6a2cc5945be97f159a1054206bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9635e7023f434d1483f123a48d4c7fb0",
              "IPY_MODEL_ede54930c0614d639512f37b49ca1920",
              "IPY_MODEL_1b96289edbe94c1da5331fdbfc6e2889"
            ],
            "layout": "IPY_MODEL_94c20baef8714f418517bfa9a8a93584"
          }
        },
        "9635e7023f434d1483f123a48d4c7fb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0d6583ce3594721b112e508383f0546",
            "placeholder": "​",
            "style": "IPY_MODEL_6e020300af634a05a8832e0b92e9216c",
            "value": "Generating train split: "
          }
        },
        "ede54930c0614d639512f37b49ca1920": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e96d631ac494403a9f47357a29da6e7",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_14ba9d0c402f40b69573d3ae94512811",
            "value": 1
          }
        },
        "1b96289edbe94c1da5331fdbfc6e2889": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_efdcd2ee787b4a24a302c4b639883889",
            "placeholder": "​",
            "style": "IPY_MODEL_a56efb7ef66d480fbea6e67db1eff517",
            "value": " 191413/0 [00:00&lt;00:00, 781313.91 examples/s]"
          }
        },
        "94c20baef8714f418517bfa9a8a93584": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0d6583ce3594721b112e508383f0546": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e020300af634a05a8832e0b92e9216c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e96d631ac494403a9f47357a29da6e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "14ba9d0c402f40b69573d3ae94512811": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "efdcd2ee787b4a24a302c4b639883889": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a56efb7ef66d480fbea6e67db1eff517": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb129d85bf6a4f228965b311a792e711": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_773ee67448194509826fc2a27db3f617",
              "IPY_MODEL_676148fc7c7440ddae89dc7a79ba7ef3",
              "IPY_MODEL_f0310138cb9a4d49b92a0f4503e5442f"
            ],
            "layout": "IPY_MODEL_fc0aefeabbea4ae4bd2785570bfbe4dc"
          }
        },
        "773ee67448194509826fc2a27db3f617": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c92d90add2e045fab512573d0eb3ff9d",
            "placeholder": "​",
            "style": "IPY_MODEL_a09d683934db45f58e891491a72b2641",
            "value": "Generating train split: "
          }
        },
        "676148fc7c7440ddae89dc7a79ba7ef3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55c88ed51f394f199dd33ba799072697",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e69334e8826042cc97c07503ba73986a",
            "value": 1
          }
        },
        "f0310138cb9a4d49b92a0f4503e5442f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7a24f48d2994d7990d66172362bb431",
            "placeholder": "​",
            "style": "IPY_MODEL_9e4855ea874e4828a8bf07dd440fa95c",
            "value": " 191413/0 [00:00&lt;00:00, 748944.22 examples/s]"
          }
        },
        "fc0aefeabbea4ae4bd2785570bfbe4dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c92d90add2e045fab512573d0eb3ff9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a09d683934db45f58e891491a72b2641": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55c88ed51f394f199dd33ba799072697": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "e69334e8826042cc97c07503ba73986a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c7a24f48d2994d7990d66172362bb431": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e4855ea874e4828a8bf07dd440fa95c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}